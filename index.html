<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Mohamed Nufais</title>

  <meta name="author" content="Mohamed Nufais">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <style>
    #myimg{
      width:100%;
      max-width:100%;
      border-radius:50%;
      border: 1px solid #ddd;
      padding: 5px;
    }

    p {
      line-height: 22px;
      font-size: 15px;
    }

    ul li{
     font-size:15px;
    }

  </style>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p id="namechange" align="center">
                  <span id="a"><name>Mohamed Nufais</name></span> <!--<span id="b" style="font-family: 'Gugi', cursive; font-size: 40px;">अक्षिता गुप्ता </span>-->
              </p>
              <p style="text-align:justify" >
                I'm an undergraduate student at the <a href="https://cmb.ac.lk/">University of Colombo</a>, studying with <a href="https://science.cmb.ac.lk/degree-programmes-we-offer-for-incoming-a-l-students/industrial-statistics-mathematical-finance/">industrial-statistics-mathematical-finance</a> under <a href="https://science.cmb.ac.lk/">Faculty Of Science</a> University Of  colombo
                And also studying external degree of  <a href="https://www.bit.lk/">Bachelor of Information Technology</a> from the University Of Colombo School Of Computing <a href="https://ucsc.cmb.ac.lk/">(UCSC)</a>. 

              </p>
              <p style="text-align:justify" >
                Previously, I done a wonderful several projects consider as E-commerce, Medical, Law and Construction.
                I currently completed my projects of Software developing sides,
                where my projects were on Learning Representations for web application Processing, completed by my own knowledge skills.
                So, I want to a internship with software engineering side during my undergraduate.
              </p>
              <p style="text-align:justify" >
                I'm interested in broader areas in Computer Vision and Machine Learning with focus in the subdomains of <strong>Self-Supervised Learning, 3D Vision, and Learning with Limited Labels (few-shot, zero-shot).</strong>
              </p>
              <br>

              <!-- <p style="text-align:justify;color:red;" >
                <b>UPDATE:</b> I'm applying for PhD positions for 2023 Fall intake. </strong>
              </p> -->

              <p style="text-align:center">
                <a href="mailto:mohamednufais678@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://github.com/MohamedNufais5891/profile/Resume/Mohamed Nufais.pdf">CV</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/mohamed-nufais-1875ba25b/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://github.com/MohamedNufais5891">Github</a>&nbsp/&nbsp
                <a href="https://www.facebook.com/mohamednufais07">Facebook</a> 
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/dp.jpeg"><img id = "myimg" alt="profile photo" src="images/dp.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
      
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="width:100%;vertical-align:middle">
            <heading>Projects</heading>
            <p style="text-align:justify" >
              I'm fascinated by the growth of computer vision community towards making the models see and understand the world as humans do.
              In particular, I'm intrigued by the results of the models learnt with self-supervision or with label constrained environments.
            </p>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/CrossPoint_Architecture.png' width="160">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle>CrossPoint: Self-Supervised Cross-Modal Contrastive Learning for 3D Point Cloud Understanding</papertitle>
            <br>
            <strong>Mohamed Afham</strong>,
            Isuru Dissanayake,
            Dinithi Dissanayake,
            Amaya Dharmasiri,
            Kanchana Thilakarathna,
            Ranga Rodrigo<br>
            <br>
            <strong>CVPR 2022</strong>
            <br>
            <a href="https://arxiv.org/abs/2203.00680">Paper</a> /
            <a href="https://github.com/MohamedAfham/CrossPoint">Code</a> /
            <a href="https://mohamedafham.github.io/CrossPoint/">Project Page</a>
            <ul>
              <li>
                <u>Description:</u> Introduced a joint learning objective encapsulating intra-modal correspondence within point cloud modality
                and cross-modal correspondence between point cloud and 2D image modalities, leveraging contrastive learning.
              </li>
              <br>
              <li>
                <u>Outcome:</u> Produced state-of-the-art performance in downstream tasks such as 3D object classification, few-shot object classification
                and 3D object part segmentation, outperforming previous unsupervised learning methods.

              </li>
            </ul>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/kts_archi.png' width="160">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle>Revisiting Kernel Temporal Segmentation as an Adaptive Tokenizer for Long-form Video Understanding</papertitle>
            <br>
            <strong>Mohamed Afham</strong>,
            Satya Narayan Shukla,
            Omid Poursaeed,
            Pengchuan Zhang,
            Ashish Shah,
            Sernam Lim<br>
            <br>
            <strong>ICCV 2023, Workshop on Resource Efficient Deep Learning for Computer Vision</strong>
            <br>
            <a href="https://arxiv.org/abs/2309.11569">Paper</a>
            <ul>
              <li>
                <u>Description:</u> We propose a task-agnostic, unsupervised and scalable approach based on Kernel Temporal Segmentation (KTS) for adaptive sampling and tokenizing long videos.
              </li>
              <br>
              <li>
                <u>Outcome:</u> Produce competitive performance on several benchmarks for long video modeling, specifically in tasks such as video classification and temporal action localization.
              </li>
            </ul>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/VS-Alignment.png' width="160">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle>Visual - Semantic Contrastive Alignment for Few-Shot Image Classification</papertitle>
            <br>
            <strong>Mohamed Afham</strong>,
            Ranga Rodrigo<br>
            <br>
            <strong>ECCV 2022, Workshop on Computer Vision in the Wild</strong>
            <br>
            <a href="https://arxiv.org/abs/2210.11000">Paper</a>
            <ul>
              <li>
                <u>Description:</u> Proposed an auxiliary multimodal contrastive learning objective between visual and semantic class
                prototypes to enhance the visual class-discriminative capability of several few-shot baselines.
              </li>
              <br>
              <li>
                <u>Outcome:</u> Outperformed the standard meta learning baselines in few-shot learning by simply plugging in the 
                proposed multimodal contrastive learning objective.
              </li>
            </ul>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/CD_HPE_Architecture.png' width="160">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle>Towards Accurate Cross-Domain In-Bed Human Pose Estimation</papertitle>
            <br>
            <strong>Mohamed Afham<sup>*</sup></strong>,
            Udith Haputhanthri<sup>*</sup>,
            Jathurshan Pradeepkumar<sup>*</sup>,
            Mithunjha Anandakumar,
            Ashwin De Silva,
            Chamira Edussooriya<br>
            (* denotes equal contribution)<br>
            <br>
            <strong>ICASSP 2022</strong>
            <br>
            <a href="https://arxiv.org/abs/2110.03578">Paper</a> /
            <a href="https://github.com/MohamedAfham/CD_HPE">Code</a>
            <ul>
              <li>
                <u>Description:</u> Proposed a novel learning strategy with two-fold data augmentation and self-supervised knowledge distillation to reduce the domain discrepancy between labeled source domain and unlabeled target domain.
              </li>
              <br>
              <li>
                <u>Outcome:</u> Improved performance on SLP dataset over two standard pose estimation baselines.
              </li>
            </ul>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/RS_FSL_Architecture.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Rich Semantics Improve Few-Shot Learning</papertitle>
              <br>
              <strong>Mohamed Afham</strong>,
              Salman Khan,
              Muhammad Haris Khan,
              Muzammal Naseer,
              Fahad Shahbaz Khan<br>
              <br>
              <strong>BMVC 2021</strong>
              <br>
              <a href="https://arxiv.org/abs/2104.12709">Paper</a> /
              <a href="https://github.com/MohamedAfham/RS_FSL">Code</a> /
              <a href="https://www.bmvc2021-virtualconference.com/conference/papers/paper_0444.html">Presentation</a>
              <ul>
                <li>
                  <u>Description:</u> Proposed a multi-modal architecture for few-shot learning  which leverages the class-level descriptions to learn better representations.
                </li>
                <br>
                <li>
                  <u>Outcome:</u> Improved state-of-the-art performances on CUB, VGG-Flowers and ShapeWorld and competitive performance on miniImagenet.
                </li>
              </ul>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tr>
              <td width="100%" valign="middle">
                <heading>Education</heading>
              </td>
            </tr>
          </table>
  
          <table border="0" cellpadding="0" cellspacing="4">
  
            <tbody><tr><td valign="top" rowspan="6"><img height="75" border="0" src="images/tud.png">
  
            </td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td valign="middle" colspan="2"><span class="h1"><b>Technical University of Darmstadt, Germany</b></span>
  
            <br><em>Master's + PhD in Computer Science</em><br>
            Oct 2023 - Present</a>
  
          </td></tr></tbody></table><br>
  
          <table border="0" cellpadding="0" cellspacing="4">
  
            <tbody><tr><td valign="top" rowspan="6"><img height="150" border="0" src="images/uom_logo.jpg">
  
            </td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td>
              <td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td valign="middle" colspan="2"><span class="h1"><b>University of Moratuwa, Sri Lanka</b></span>
  
            <br><em>Bachelor's in Science (Engineering) specialized in Electronics and Telecommunication</em><br>
            Aug 2017 - Jul 2022</a>
  
          </td></tr></tbody></table><br>
  
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
            <br>
            <p align="right">
              <font size="2">
              <strong>I have used this websites layout  <a target="_blank" href="https://jonbarron.info/">here</a>!</strong>
          </font>
            </p>
            </td>
          </tr>
          </table>
      </td>
    </tr>
  </table>
</body>

</html>